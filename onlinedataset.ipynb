{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2Fh2iH1u/tLjO43pAMuCu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruthu06/Pattern-Recognition-and-Data-Mining/blob/main/onlinedataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "8VVM4rKovAdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMzzDMSTK46C"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_excel('/content/online_shoppers_data.xlsx')\n",
        "\n",
        "def calculate_page_values_per_product_dur(row):\n",
        "    if row['ProductRelated_Duration'] != 0:\n",
        "        return row['PageValues'] / row['ProductRelated_Duration']\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "def calculate_page_values_per_product_view(row):\n",
        "    if row['ProductRelated_Duration'] != 0:\n",
        "        return row['PageValues'] / row['ProductRelated']\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "df['page_values_per_product_dur'] = df.apply(calculate_page_values_per_product_dur, axis=1)\n",
        "df['page_values_per_product_view'] = df.apply(calculate_page_values_per_product_view, axis=1)\n",
        "# Write the modified DataFrame back to the Excel file\n",
        "df.to_excel('/content/online_shoppers_intention_with_calculations.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel('/content/AUGMENTED_DATA_TRUE.xlsx')\n",
        "\n",
        "df.drop(columns=[ 'Region', 'Browser', 'TrafficType'], inplace=True)\n",
        "columns_to_encode = ['Month', 'VisitorType', 'Weekend','DurationPeriod','Seasons']\n",
        "\n",
        "# Perform one-hot encoding for selected columns\n",
        "df_encoded = pd.get_dummies(df, columns=columns_to_encode)\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = df_encoded.drop(columns=['Revenue'])\n",
        "y = df['Revenue']\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "# Split the dataset into training (70%), validation (15%), and test (15%) sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and train a machine learning model (Random Forest Classifier in this example)\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Validate the model using the validation set\n",
        "y_val_pred = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "y_test_pred = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Assuming y_test and y_pred are your actual labels and predicted labels, respectively\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Recall:\", recall)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU8RUVx8eLtb",
        "outputId": "51d8f243-56bb-4de3-d460-5f0c0b04c353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.94293210888816\n",
            "Test Accuracy: 0.9406557377049181\n",
            "Recall: 0.9311010946555055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances from the trained model\n",
        "feature_importances = model.feature_importances_\n",
        "\n",
        "# Create a DataFrame to store feature importances along with corresponding column names\n",
        "importance_df = pd.DataFrame({'Feature': df_encoded.drop(columns=['Revenue']).columns,\n",
        "                              'Importance': feature_importances})\n",
        "\n",
        "# Sort the DataFrame by importance values in descending order\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print or visualize the top N most important features\n",
        "top_n = 10  # Specify the number of top features you want to display\n",
        "print(\"Top\", top_n, \"Most Important Features:\")\n",
        "print(importance_df.head(top_n))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ2p9PX3-05Q",
        "outputId": "8572508c-78cc-4f3d-b0c5-f2afabb9d621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Most Important Features:\n",
            "                           Feature  Importance\n",
            "8                       PageValues    0.151336\n",
            "14    page_values_per_product_view    0.117122\n",
            "13     page_values_per_product_dur    0.084908\n",
            "2976                   Weekend_0.0    0.065211\n",
            "6                      BounceRates    0.060194\n",
            "7                        ExitRates    0.053332\n",
            "9                       SpecialDay    0.052474\n",
            "3           Informational_Duration    0.051385\n",
            "2                    Informational    0.046133\n",
            "1          Administrative_Duration    0.035806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [80,100,120],\n",
        "    'max_depth': [None, 10,12,15],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "# Create the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_accuracy = grid_search.score(X_val, y_val)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_cf8b2tu4Pj",
        "outputId": "ee4d81bc-0912-4752-ad94-176e447b7cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 12, 'max_features': 'auto', 'min_samples_split': 5, 'n_estimators': 120}\n",
            "Test Accuracy: 0.9422761561167596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel('/content/AUGMENTED_DATA_TRUE.xlsx')\n",
        "\n",
        "# Drop columns\n",
        "df.drop(columns=['Month', 'Region', 'Browser', 'DurationPeriod', 'Seasons', 'TrafficType', 'VisitorType'], inplace=True)\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = df.drop(columns=['Revenue'])\n",
        "y = df['Revenue']\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training (70%), validation (15%), and test (15%) sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and train a machine learning model (Gradient Boosting Machine in this example)\n",
        "model = GradientBoostingClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Validate the model using the validation set\n",
        "y_val_pred = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(\"Validation Accuracy (Gradient Boosting Machine):\", val_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOSe8kKK_NK5",
        "outputId": "a058bf2b-ee8c-4712-82fd-e9bfe85266e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (Gradient Boosting Machine): 0.9383404394883569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [60,80, 100],\n",
        "    'max_depth': [ 5,6, 7],  # Adjusted max_depth for Gradient Boosting\n",
        "    'min_samples_split': [2,3, 5],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "# Create the Gradient Boosting classifier\n",
        "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=gb_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate on the validation set\n",
        "val_accuracy = grid_search.best_estimator_.score(X_val, y_val)\n",
        "print(\"Validation Accuracy (Gradient Boosting Machine):\", val_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk96kGK5_0yN",
        "outputId": "5874a534-490f-4140-acf1-68a970c0f555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 6, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Validation Accuracy (Gradient Boosting Machine): 0.9419481797310594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize and train a machine learning model (Decision Tree Classifier in this example)\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Validate the model using the validation set\n",
        "y_val_pred_dt = dt_model.predict(X_val)\n",
        "val_accuracy_dt = accuracy_score(y_val, y_val_pred_dt)\n",
        "print(\"Validation Accuracy (Decision Tree):\", val_accuracy_dt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW7mavf7Eemf",
        "outputId": "1ac3c346-74a5-423d-ff86-b3b68f949041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (Decision Tree): 0.9130862577894392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define the parameter grid for Decision Tree\n",
        "param_grid_dt = {\n",
        "    'max_depth': [5, 6, 7],\n",
        "    'min_samples_split': [2, 3, 5],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "# Create the Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Perform GridSearchCV for Decision Tree\n",
        "grid_search_dt = GridSearchCV(estimator=dt_classifier, param_grid=param_grid_dt, cv=5, scoring='accuracy')\n",
        "grid_search_dt.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters for Decision Tree\n",
        "print(\"Best Hyperparameters (Decision Tree):\", grid_search_dt.best_params_)\n",
        "\n",
        "# Evaluate Decision Tree on the validation set\n",
        "val_accuracy_dt = grid_search_dt.best_estimator_.score(X_val, y_val)\n",
        "print(\"Validation Accuracy (Decision Tree):\", val_accuracy_dt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4dcb-uwEo36",
        "outputId": "db4262a9-bc82-4c71-8a46-1e0431e99afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters (Decision Tree): {'max_depth': 7, 'max_features': 'auto', 'min_samples_split': 2}\n",
            "Validation Accuracy (Decision Tree): 0.8934559221200649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize individual classifiers\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Create the ensemble using VotingClassifier\n",
        "ensemble_classifier = VotingClassifier(estimators=[\n",
        "    ('rf', rf_classifier),\n",
        "    ('gb', gb_classifier),\n",
        "    ('dt', dt_classifier)\n",
        "], voting='hard')  # 'hard' voting means majority voting\n",
        "\n",
        "# Train the ensemble on the training data\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred_ensemble = ensemble_classifier.predict(X_val)\n",
        "\n",
        "# Calculate validation accuracy\n",
        "val_accuracy_ensemble = accuracy_score(y_val, y_val_pred_ensemble)\n",
        "print(\"Validation Accuracy (Ensemble):\", val_accuracy_ensemble)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGzKMKtuJzIq",
        "outputId": "c255dd2e-ee83-4468-b971-49909936a09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (Ensemble): 0.9406362741882585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Initialize individual classifiers\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Create the ensemble using VotingClassifier\n",
        "ensemble_classifier = VotingClassifier(estimators=[\n",
        "    ('rf', rf_classifier),\n",
        "    ('gb', gb_classifier),\n",
        "    ('dt', dt_classifier)\n",
        "], voting='hard')  # 'hard' voting means majority voting\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(ensemble_classifier, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean Accuracy:\", cv_scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIiKGgJFKCSc",
        "outputId": "0f8fe770-a603-4afb-fea3-bce2049d2618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.93572181 0.93183415 0.93042867 0.93780745 0.93640197]\n",
            "Mean Accuracy: 0.9344388108353876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize RandomOverSampler for oversampling\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "\n",
        "# Fit and apply oversampling to the training data\n",
        "X_train_resampled_over, y_train_resampled_over = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Initialize RandomUnderSampler for undersampling\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "\n",
        "# Fit and apply undersampling to the training data\n",
        "X_train_resampled_under, y_train_resampled_under = undersampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "\n",
        "# Convert class weights to dictionary\n",
        "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
        "\n",
        "# Initialize RandomForestClassifier with oversampling\n",
        "rf_classifier_over = RandomForestClassifier(random_state=42)\n",
        "rf_classifier_over.fit(X_train_resampled_over, y_train_resampled_over)\n",
        "\n",
        "# Initialize RandomForestClassifier with undersampling\n",
        "rf_classifier_under = RandomForestClassifier(random_state=42)\n",
        "rf_classifier_under.fit(X_train_resampled_under, y_train_resampled_under)\n",
        "\n",
        "# Initialize RandomForestClassifier with class weights\n",
        "rf_classifier_weighted = RandomForestClassifier(random_state=42, class_weight=class_weight_dict)\n",
        "rf_classifier_weighted.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Predict on the test set using classifiers trained with different techniques\n",
        "y_pred_over = rf_classifier_over.predict(X_test)\n",
        "y_pred_under = rf_classifier_under.predict(X_test)\n",
        "y_pred_weighted = rf_classifier_weighted.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for each classifier\n",
        "accuracy_over = accuracy_score(y_test, y_pred_over)\n",
        "accuracy_under = accuracy_score(y_test, y_pred_under)\n",
        "accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
        "\n",
        "print(\"Accuracy (RandomForest with oversampling):\", accuracy_over)\n",
        "print(\"Accuracy (RandomForest with undersampling):\", accuracy_under)\n",
        "print(\"Accuracy (RandomForest with class weights):\", accuracy_weighted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvZITBnqKOTf",
        "outputId": "8541b5ad-a1e0-4061-a2a5-c97b2901a8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (RandomForest with oversampling): 0.8913513513513514\n",
            "Accuracy (RandomForest with undersampling): 0.8491891891891892\n",
            "Accuracy (RandomForest with class weights): 0.8902702702702703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Initialize GradientBoostingClassifier with oversampling\n",
        "gb_classifier_over = GradientBoostingClassifier(random_state=42)\n",
        "gb_classifier_over.fit(X_train_resampled_over, y_train_resampled_over)\n",
        "\n",
        "# Initialize GradientBoostingClassifier with undersampling\n",
        "gb_classifier_under = GradientBoostingClassifier(random_state=42)\n",
        "gb_classifier_under.fit(X_train_resampled_under, y_train_resampled_under)\n",
        "\n",
        "# Initialize GradientBoostingClassifier with class weights\n",
        "gb_classifier_weighted = GradientBoostingClassifier(random_state=42)\n",
        "gb_classifier_weighted.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using GradientBoostingClassifier trained with different techniques\n",
        "y_pred_over_gb = gb_classifier_over.predict(X_test)\n",
        "y_pred_under_gb = gb_classifier_under.predict(X_test)\n",
        "y_pred_weighted_gb = gb_classifier_weighted.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for each GradientBoostingClassifier\n",
        "accuracy_over_gb = accuracy_score(y_test, y_pred_over_gb)\n",
        "accuracy_under_gb = accuracy_score(y_test, y_pred_under_gb)\n",
        "accuracy_weighted_gb = accuracy_score(y_test, y_pred_weighted_gb)\n",
        "\n",
        "print(\"Accuracy (GradientBoosting with oversampling):\", accuracy_over_gb)\n",
        "print(\"Accuracy (GradientBoosting with undersampling):\", accuracy_under_gb)\n",
        "print(\"Accuracy (GradientBoosting with class weights):\", accuracy_weighted_gb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsTbcuV8KXqm",
        "outputId": "5371bad6-bb8f-4002-e3e3-9a3dd2fb3606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (GradientBoosting with oversampling): 0.8594594594594595\n",
            "Accuracy (GradientBoosting with undersampling): 0.86\n",
            "Accuracy (GradientBoosting with class weights): 0.8967567567567568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize DecisionTreeClassifier with oversampling\n",
        "dt_classifier_over = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier_over.fit(X_train_resampled_over, y_train_resampled_over)\n",
        "\n",
        "# Initialize DecisionTreeClassifier with undersampling\n",
        "dt_classifier_under = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier_under.fit(X_train_resampled_under, y_train_resampled_under)\n",
        "\n",
        "# Initialize DecisionTreeClassifier with class weights\n",
        "dt_classifier_weighted = DecisionTreeClassifier(random_state=42, class_weight=class_weight_dict)\n",
        "dt_classifier_weighted.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using DecisionTreeClassifier trained with different techniques\n",
        "y_pred_over_dt = dt_classifier_over.predict(X_test)\n",
        "y_pred_under_dt = dt_classifier_under.predict(X_test)\n",
        "y_pred_weighted_dt = dt_classifier_weighted.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for each DecisionTreeClassifier\n",
        "accuracy_over_dt = accuracy_score(y_test, y_pred_over_dt)\n",
        "accuracy_under_dt = accuracy_score(y_test, y_pred_under_dt)\n",
        "accuracy_weighted_dt = accuracy_score(y_test, y_pred_weighted_dt)\n",
        "\n",
        "print(\"Accuracy (DecisionTree with oversampling):\", accuracy_over_dt)\n",
        "print(\"Accuracy (DecisionTree with undersampling):\", accuracy_under_dt)\n",
        "print(\"Accuracy (DecisionTree with class weights):\", accuracy_weighted_dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uygC1CXKbqX",
        "outputId": "7665976c-254e-4421-c2b3-4f4e3cdb39c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (DecisionTree with oversampling): 0.8551351351351352\n",
            "Accuracy (DecisionTree with undersampling): 0.7924324324324324\n",
            "Accuracy (DecisionTree with class weights): 0.8545945945945946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Initialize VotingClassifier with RandomForestClassifier, GradientBoostingClassifier, and DecisionTreeClassifier trained with different techniques\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "    ('rf_over', rf_classifier_over),\n",
        "    ('rf_under', rf_classifier_under),\n",
        "    ('rf_weighted', rf_classifier_weighted),\n",
        "    ('gb_over', gb_classifier_over),\n",
        "    ('gb_under', gb_classifier_under),\n",
        "    ('gb_weighted', gb_classifier_weighted),\n",
        "    ('dt_over', dt_classifier_over),\n",
        "    ('dt_under', dt_classifier_under),\n",
        "    ('dt_weighted', dt_classifier_weighted)\n",
        "], voting='soft')  # 'hard' voting means majority voting\n",
        "\n",
        "# Train the VotingClassifier\n",
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the VotingClassifier\n",
        "y_pred_voting = voting_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for the VotingClassifier\n",
        "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
        "\n",
        "print(\"Accuracy (VotingClassifier):\", accuracy_voting)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQtUCgwoKiKz",
        "outputId": "688be06a-314a-4cbd-8ae2-2ee377371568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (VotingClassifier): 0.8897297297297297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_excel('/content/online_shoppers_intention_with_calculations (1).xlsx')  # Replace with the path to your Excel file\n",
        "\n",
        "# Separate the dataset into true and false samples\n",
        "true_samples = df[df['Revenue'] == True]\n",
        "false_samples = df[df['Revenue'] == False]\n",
        "\n",
        "num_additional_true_samples = 8000\n",
        "augmented_true_samples = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "for _ in range(num_additional_true_samples):\n",
        "    # Randomly select a true sample\n",
        "    sample = true_samples.iloc[np.random.randint(0, len(true_samples))]\n",
        "\n",
        "    # Augment the sample by adding noise to numerical columns (excluding 'Revenue' column)\n",
        "    for col in df.select_dtypes(include=np.number).columns:\n",
        "        if col != 'Revenue':\n",
        "            noise = np.random.normal(scale=0.1)  # Adjust the scale of noise as needed\n",
        "            sample[col] += noise\n",
        "\n",
        "    augmented_true_samples = augmented_true_samples.append(sample, ignore_index=True)\n",
        "\n",
        "augmented_df = pd.concat([true_samples, augmented_true_samples, false_samples], ignore_index=True)\n",
        "\n",
        "# Save the augmented data to a new Excel file\n",
        "augmented_df.to_excel('/content/online_shoppers_intention_with_calculations (24).xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "u9ucGslvS7YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC())\n",
        "])\n",
        "\n",
        "# Define the hyperparameters to search\n",
        "param_grid = {\n",
        "    'svm__kernel': ['linear', 'rbf', 'poly'],\n",
        "    'svm__C': [0.1, 1, 10],\n",
        "    'svm__gamma': [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy - SVM:\", accuracy)"
      ],
      "metadata": {
        "id": "wcMjdXpAdywN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}